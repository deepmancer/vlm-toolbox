{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7795548e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc7e716-f7f4-42a8-bdec-0a40a4b2d405",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../vlm_toolbox/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec644e8-79c4-41df-9187-7f11e765181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3406a0cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from config.enums import ImageDatasets, ModelType, Setups, Trainers\n",
    "from config.metric import MetricIOConfig\n",
    "from config.path import ANNOTATIONS_TEMPLATE_PATH\n",
    "from config.setup import Setup\n",
    "from metric.visualization.accuracy import plot_model_accuracy\n",
    "from pipeline.pipeline import Pipeline\n",
    "from util.logging import LoggerFactory\n",
    "from util.numpy_helper import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d85c67-802e-4e38-8330-5346e81a5ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959be6b9-c2be-4f5b-98d7-0722f62c84f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flush():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3c82c9",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f62c26-6131-4e10-9ba7-541b254c6e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE_TYPE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE = torch.device(DEVICE_TYPE)\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f799a8-4100-4913-b55d-0cb74d1f1375",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = LoggerFactory.create_logger(name='pipeline', notebook=True, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630bd48f-d11b-435f-91e0-c2eba8e3296d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SETUP_DEFAULTS = {\n",
    "    \"dataset_name\": ImageDatasets.IMAGENET_1K,\n",
    "    \"trainer_name\": Trainers.COOP,\n",
    "    \"n_shots\": 16,\n",
    "    # \"annotations_key_value_criteria\": {'kingdom': ['Animalia']}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6f2fa9-bdaa-422f-87f0-715ae64495bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ANNOTATIONS_PATH = ANNOTATIONS_TEMPLATE_PATH + SETUP_DEFAULTS['dataset_name'] + '/labels.csv'\n",
    "TOP_K = 5\n",
    "\n",
    "HIERARCHY_LEVELS = {\n",
    "    'coarse': None,\n",
    "    'default': 'coarse'\n",
    "}\n",
    "\n",
    "REVERSED_HIERARCHY_LEVELS = {\n",
    "    'coarse': 'default',\n",
    "    'default': None,\n",
    "}\n",
    "\n",
    "\n",
    "# HIERARCHY_LEVELS = {\n",
    "#     'phylum': None,\n",
    "#     'class': 'phylum',\n",
    "#     'order': 'class',\n",
    "#     'family': 'order',\n",
    "#     # 'genus': 'family',\n",
    "#     # 'specific_epithet': 'genus',\n",
    "#     'default': 'family'\n",
    "# }\n",
    "\n",
    "# REVERSED_HIERARCHY_LEVELS = {\n",
    "#     'phylum': 'class',\n",
    "#     'class': 'order',\n",
    "#     'order': 'family',\n",
    "#     'family': 'default',\n",
    "#     # 'genus': 'specific_epithet',\n",
    "#     # 'specific_epithet': 'default',\n",
    "#     'default': None,\n",
    "# }\n",
    "\n",
    "\n",
    "# LEVELS_TOP_N_CHILDREN_TO_PROPAGATE = {\n",
    "#     'phylum': 2,\n",
    "#     'class': 4,\n",
    "#     'order': 2,\n",
    "#     'family': 3,\n",
    "#     # 'genus': 4,\n",
    "#     # 'specific_epithet': 4,\n",
    "#     'default': TOP_K,\n",
    "# }\n",
    "\n",
    "LEVEL_NAMES = list(HIERARCHY_LEVELS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41767ff3-2483-4745-813d-22abf045690b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_complemented_labels_df(path=ANNOTATIONS_PATH, levels=LEVEL_NAMES, logger=logger, setup_defaults=SETUP_DEFAULTS):\n",
    "    labels_df = pd.read_csv(path)\n",
    "    labels_df = labels_df.rename(columns={'simplified': 'default', 'class_id': 'label_id'})\n",
    "    for col, values in setup_defaults.get('annotations_key_value_criteria', {}).items():\n",
    "        labels_df = labels_df[labels_df[col].isin(values)]\n",
    "\n",
    "    for level in levels:\n",
    "        labels_df[level] = labels_df[level].apply(lambda value: value.lower())\n",
    "    labels_df = labels_df[['label_id', *levels]]\n",
    "    \n",
    "    for i, level in enumerate(levels):\n",
    "        is_root = i == 0\n",
    "        is_leaf = level == 'default'\n",
    "        setup = Setup(\n",
    "            **setup_defaults,\n",
    "            setup_type=Setups.EVAL_ONLY  if not is_leaf else Setups.FULL,\n",
    "            model_type=ModelType.ZERO_SHOT if not is_leaf else ModelType.FEW_SHOT,\n",
    "            label_column_name=level if not is_leaf else None,\n",
    "            top_k=len(labels_df[level].value_counts()),\n",
    "        )\n",
    "        pipeline = Pipeline(setup, device_type=DEVICE_TYPE, logger=logger)\n",
    "        pipeline.setup_labels()\n",
    "        level_labels_df = pipeline.label_handler.get_labels_df()\n",
    "        pipeline.tear_down()\n",
    "        labels_df = labels_df.merge(\n",
    "            level_labels_df.rename(columns={\n",
    "                'label_id': f'{level}_label_id',\n",
    "                'label': level,\n",
    "            }),\n",
    "            on=level,\n",
    "            how='left'\n",
    "        )\n",
    "    return labels_df\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f3987b-97ab-4ba4-8a34-c9dfa7ec2bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a0d9b3-8345-49f9-990c-a900a5ec6e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = create_complemented_labels_df()\n",
    "per_level_cnt = {col: labels_df[col].nunique() for col in LEVEL_NAMES}\n",
    "per_level_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ba9216-2b28-4680-9d86-c467ea21d0c1",
   "metadata": {},
   "source": [
    "# Create & Process Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5af6b26-37e9-499f-9847-143777d2d9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, label, label_id, level):\n",
    "        self.label = label\n",
    "        self.label_id = label_id\n",
    "        self.level = level\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.label_id, self.level))\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (self.level == other.level) and (self.label_id == other.label_id or self.label == other.label)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}(level={self.level}, label={self.label}, label_id={self.label_id})\"\n",
    "\n",
    "def create_labels_graph(df, levels=LEVEL_NAMES):\n",
    "    G = nx.DiGraph()\n",
    "    label_ids = [f\"{l}_label_id\" for l in levels]\n",
    "    for index, row in df.iterrows():\n",
    "        previous_node = None\n",
    "        for level, label_id_field in zip(levels, label_ids):\n",
    "            label = row[level]\n",
    "            label_id = row[label_id_field]\n",
    "            node = Node(label, label_id, level)\n",
    "            G.add_node(node)\n",
    "            if previous_node:\n",
    "                G.add_edge(previous_node, node)\n",
    "            previous_node = node\n",
    "\n",
    "    return G\n",
    "    \n",
    "def get_to_children_mapping(level, labels_df=labels_df, reversed_hierarchy=REVERSED_HIERARCHY_LEVELS):\n",
    "    source_col = f\"{level}_label_id\"\n",
    "    dest_col = f\"{reversed_hierarchy[level]}_label_id\"\n",
    "    mapping_df = labels_df[[source_col, dest_col]].drop_duplicates(keep='first').sort_values(by=source_col).reset_index(drop=True)\n",
    "    return mapping_df.groupby(source_col)[dest_col].apply(list).to_dict()\n",
    "\n",
    "  \n",
    "def get_to_children_cnt_mapping(level, labels_df=labels_df, reversed_hierarchy=REVERSED_HIERARCHY_LEVELS):\n",
    "    source_col = f\"{level}_label_id\"\n",
    "    dest_col = f\"{reversed_hierarchy[level]}_label_id\"\n",
    "    mapping_df = labels_df[[source_col, dest_col]].drop_duplicates(keep='first').sort_values(by=source_col).reset_index(drop=True)\n",
    "    return {k: len(v) for k, v in mapping_df.groupby(source_col)[dest_col].apply(list).to_dict().items()}\n",
    "\n",
    "def get_to_parent_mapping(level, labels_df=labels_df, hierarchy=REVERSED_HIERARCHY_LEVELS):\n",
    "    source_col = f\"{level}_label_id\"\n",
    "    dest_col = f\"{hierarchy[level]}_label_id\"\n",
    "    mapping_df = labels_df[[source_col, dest_col]].drop_duplicates(keep='first').sort_values(by=source_col).reset_index(drop=True)\n",
    "    return {k: len(v) for k, v in mapping_df.groupby(source_col)[dest_col].apply(list).to_dict().items()}\n",
    "\n",
    "def get_to_parent_cnt_mapping(level, labels_df=labels_df, hierarchy=REVERSED_HIERARCHY_LEVELS):\n",
    "    source_col = f\"{level}_label_id\"\n",
    "    dest_col = f\"{hierarchy[level]}_label_id\"\n",
    "    mapping_df = labels_df[[source_col, dest_col]].drop_duplicates(keep='first').sort_values(by=source_col).reset_index(drop=True)\n",
    "    return mapping_df.groupby(source_col)[dest_col].apply(list).to_dict()\n",
    "\n",
    "\n",
    "def get_node(G, level, label=None, label_id=None):\n",
    "    if label and label_id:\n",
    "        return Node(label, label_id, level)\n",
    "    search_node = Node(label, label_id, level)\n",
    "    for node in G.nodes:\n",
    "        if node == search_node:\n",
    "            return node\n",
    "\n",
    "def get_parent(G, level, label=None, label_id=None):\n",
    "    search_node = get_node(G, level, label, label_id)\n",
    "    parent = [node for node in G.predecessors(search_node)]\n",
    "    return parent[0] if len(parent) else None\n",
    "\n",
    "def get_parents_to_root(G, level, label=None, label_id=None):\n",
    "    search_node = get_node(G, level, label, label_id)\n",
    "    parents = []\n",
    "    while True:\n",
    "        parent = get_parent(G, search_node.level, search_node.label, search_node.label_id)\n",
    "        if not parent:\n",
    "            break\n",
    "        parents.append(parent)\n",
    "        search_node = parent\n",
    "    return parents\n",
    "\n",
    "def get_children(G, level, label=None, label_id=None):\n",
    "    search_node = get_node(G, level, label, label_id)\n",
    "    children = [node for node in G.successors(search_node)]\n",
    "    return children if len(children) else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989e6c3a-cddc-466a-ace3-038c2d405a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_graph = create_labels_graph(labels_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de335e43-76b7-46c3-a087-d4251e8be3d3",
   "metadata": {},
   "source": [
    "# Load All Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e258dc2-5f39-45d1-9009-1707cb2549f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_process_prediction_df(setup, top_k=None):\n",
    "    path = MetricIOConfig.get_config(setup) + 'per_sample.parquet'\n",
    "    print(path)\n",
    "    top_k = top_k or setup.get_top_k()\n",
    "    prediction_df = pd.read_parquet(path).reset_index(drop=True).reset_index(drop=False).rename(columns={'index': 'dataset_idx'})\n",
    "    prediction_df['label_id'] = prediction_df['actual_label_id']\n",
    "    is_correct_series = prediction_df['label_id'] == prediction_df[f'pred@1_label_id']\n",
    "    preds_ids_columns = [f\"pred@{k+1}_label_id\" for k in range(top_k)]\n",
    "    preds_prob_columns = [f\"pred@{k+1}_prob\" for k in range(top_k)]\n",
    "    static_columns = ['dataset_idx', 'class_id', 'label_id']\n",
    "    cleaned_prediction_df = prediction_df[static_columns].copy()\n",
    "    label_ids = prediction_df[preds_ids_columns].values\n",
    "    probs = prediction_df[preds_prob_columns].values\n",
    " \n",
    "    sorted_idx = np.argsort(label_ids, axis=1)\n",
    "    sorted_probs = np.take_along_axis(probs, sorted_idx, axis=1).astype(np.float16)\n",
    "    sorted_label_ids = np.take_along_axis(label_ids, sorted_idx, axis=1)\n",
    "\n",
    "    cleaned_prediction_df['probs'] = list(sorted_probs)\n",
    "    cleaned_prediction_df['is_correct'] = is_correct_series\n",
    "    return cleaned_prediction_df\n",
    "\n",
    "def load_all_predictions(path=ANNOTATIONS_PATH, levels=LEVEL_NAMES, setup_defaults=SETUP_DEFAULTS, top_k=None):\n",
    "    predictions_dict = {}\n",
    "    for i, level in enumerate(levels):\n",
    "        is_root, is_leaf = i == 0, i == len(levels) - 1\n",
    "        setup = Setup(\n",
    "            **setup_defaults,\n",
    "            model_type=ModelType.FEW_SHOT if not is_leaf else ModelType.PRETRAINED,\n",
    "            label_column_name=level if not is_leaf else None,\n",
    "            top_k=len(labels_df[level].value_counts()),\n",
    "        )\n",
    "        predictions_dict[level] = load_and_process_prediction_df(setup, top_k=top_k)\n",
    "    return predictions_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353e06bf-9131-4269-908e-0ed4df7879ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dfs = load_all_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdb2456-1107-48b0-8e59-c8830849a920",
   "metadata": {},
   "source": [
    "# Top-Down Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f912c3d-9fcc-4558-847b-444b12946383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_hierarchical_prediction(\n",
    "    prediction_dfs=prediction_dfs,\n",
    "    labels_df=labels_df,\n",
    "    labels_graph=labels_graph,\n",
    "    levels=LEVEL_NAMES,\n",
    "    top_n_dict={},\n",
    "):\n",
    "    def initialize_label_ids(df):\n",
    "        shape = df.iloc[0]['probs'].shape[0]\n",
    "        label_ids = np.arange(shape)\n",
    "        df['label_ids'] = [label_ids for _ in range(df.shape[0])]\n",
    "\n",
    "    def add_prediction_stats(df, top_n):\n",
    "        final_df = df[['dataset_idx', 'class_id', 'label_id']].copy()\n",
    "        for k in range(top_n):\n",
    "            final_df[f\"pred@{k+1}_label_id\"] = df['top_label_ids'].apply(lambda x: x[k] if k < len(x) else None)\n",
    "            final_df[f\"pred@{k+1}_prob\"] = df['probs'].apply(lambda x: x[k] if k < len(x) else None)\n",
    "\n",
    "        def find_correct_prediction_rank(row):\n",
    "            label_id = row['label_id']\n",
    "            for k in range(top_n):\n",
    "                if row.get(f\"pred@{k+1}_label_id\") == label_id:\n",
    "                    return k + 1\n",
    "            return -1\n",
    "\n",
    "        final_df['correct_pred_rank'] = final_df.apply(find_correct_prediction_rank, axis=1)\n",
    "        return final_df\n",
    "\n",
    "    def get_accuracy_df(df, top_n):\n",
    "        final_df = add_prediction_stats(df, top_n)\n",
    "        accuracies_dict = {'accuracy': [], 'top_k': []}\n",
    "        for k in range(1, top_n + 1):\n",
    "            accuracy_k = final_df['correct_pred_rank'].apply(lambda x: x <= k and x != -1).mean()\n",
    "            accuracies_dict['accuracy'].append(accuracy_k)\n",
    "            accuracies_dict['top_k'].append(k)\n",
    "\n",
    "        accuracies_df = pd.DataFrame(accuracies_dict)\n",
    "        return accuracies_df\n",
    "\n",
    "    def sorted_top_n_indices(arr, n):\n",
    "        return np.argsort(-np.array(arr))[:n]\n",
    "\n",
    "    def get_next_label_ids(label_ids, mapping_dict):\n",
    "        next_ids = set()\n",
    "        for label_id in label_ids:\n",
    "            next_ids.update(mapping_dict.get(label_id, []))\n",
    "        return list(next_ids)\n",
    "\n",
    "    def fetch_probabilities_by_indices(df, next_label_ids):\n",
    "        return [df.iloc[idx]['probs'][indices] for idx, indices in enumerate(next_label_ids)]\n",
    "\n",
    "    def get_next_label_ids(label_ids, mapping_dict):\n",
    "        next_ids = set()\n",
    "        for label_id in label_ids:\n",
    "            next_ids.update(mapping_dict.get(label_id, []))\n",
    "        return list(next_ids)\n",
    "\n",
    "    def get_propagation_coefficient(row, cnt_mapping_dict):\n",
    "        ids = row['top_label_ids']\n",
    "        probs = row['probs']\n",
    "        next_props_coefficients = []\n",
    "        for label_id, prob in zip(ids, probs):\n",
    "            next_cnt = cnt_mapping_dict.get(label_id, 0)\n",
    "            array = np.full(next_cnt, prob)\n",
    "            # array = np.ones(next_cnt)\n",
    "            next_props_coefficients.extend(array)\n",
    "        \n",
    "        return softmax(np.array(next_props_coefficients))\n",
    "\n",
    "    df_dict = {level: prediction_dfs[level].copy() for level in levels}\n",
    "    level_wise_accuracies_df = {}\n",
    "    current_predictions = df_dict[levels[0]].copy()\n",
    "    initialize_label_ids(current_predictions)\n",
    "    trace_df = current_predictions[['dataset_idx', 'class_id']].copy()\n",
    "    trace_columns = []\n",
    "\n",
    "    for i in tqdm(range(len(levels)), desc=\"Processing Levels\"):\n",
    "        current_level = levels[i]\n",
    "        top_n = top_n_dict[current_level]\n",
    "\n",
    "        current_predictions['probs'] = current_predictions['probs'].apply(softmax)\n",
    "\n",
    "        current_predictions['top_indices'] = current_predictions['probs'].apply(\n",
    "            lambda x: sorted_top_n_indices(x, top_n)\n",
    "        )\n",
    "        current_predictions['top_label_ids'] = current_predictions.apply(\n",
    "            lambda x: [x['label_ids'][idx] for idx in x['top_indices']], axis=1,\n",
    "        )\n",
    "        trace_df[f\"{current_level}_top_label_ids\"] = current_predictions['top_label_ids'].copy()\n",
    "        trace_df[f\"{current_level}_top_probs\"] = current_predictions['probs'].copy()\n",
    "\n",
    "        level_wise_accuracies_df[current_level] = get_accuracy_df(current_predictions, top_n)\n",
    "\n",
    "        if i == len(levels) - 1:\n",
    "            continue\n",
    "        \n",
    "        next_level = levels[i+1]\n",
    "        \n",
    "        mapping_children = get_to_children_mapping(current_level)\n",
    "        mapping_children_cnt = {k: len(v) for k, v in mapping_children.items()}\n",
    "\n",
    "        next_predictions = df_dict[next_level].copy()\n",
    "        \n",
    "        current_predictions['next_label_ids'] = current_predictions['top_label_ids'].apply(\n",
    "            lambda ids: get_next_label_ids(ids, mapping_children),\n",
    "        )\n",
    "        \n",
    "        current_predictions['propagation_coefficients'] = current_predictions.apply(\n",
    "            lambda row: get_propagation_coefficient(row, mapping_children_cnt),\n",
    "            axis=1,\n",
    "        )\n",
    "        \n",
    "        current_predictions['probs'] = fetch_probabilities_by_indices(next_predictions, current_predictions['next_label_ids'])\n",
    "        current_predictions['probs'] = current_predictions.apply(\n",
    "            lambda row: row['probs'] * row['propagation_coefficients'],\n",
    "            axis=1,\n",
    "        )    \n",
    "        current_predictions['label_ids'] = current_predictions['next_label_ids']\n",
    "        current_predictions['label_id'] = next_predictions['label_id']\n",
    "\n",
    "    final_leaf_df = add_prediction_stats(current_predictions, top_n_dict[levels[-1]])\n",
    "    trace_df['trace'] = final_leaf_df['pred@1_label_id'].apply(lambda label_id: get_parents_to_root(labels_graph, levels[-1], label_id=label_id))\n",
    "    return level_wise_accuracies_df, trace_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e78b2d-9d45-4d54-ad7b-a6028d007a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k = 3\n",
    "top_n_dict = {\n",
    "    'coarse': 5,\n",
    "    'default': top_k,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2e2a7a-8e3a-4fc0-bc9c-ef6072c2afa6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "level_wise_acc_df, trace_df = perform_hierarchical_prediction(top_n_dict=top_n_dict)\n",
    "level_wise_acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87db3d22-98fb-4d9e-b83f-f828bb8ccaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(LEVEL_NAMES):\n",
    "    clip_setup = Setup(\n",
    "        dataset_name=ImageDatasets.INATURALIST,\n",
    "        trainer_name=Trainers.CLIP,\n",
    "        setup_type=Setups.EVAL_ONLY,\n",
    "        label_column_name=col,\n",
    "        annotations_key_value_criteria={'kingdom': ['Animalia']},\n",
    "        top_k=TOP_K,\n",
    "    )\n",
    "    baseline_coop_setup = Setup(\n",
    "        dataset_name=ImageDatasets.INATURALIST,\n",
    "        trainer_name=Trainers.COOP,\n",
    "        n_shots=16,\n",
    "        setup_type=Setups.EVAL_ONLY,\n",
    "        model_type=ModelType.ZERO_SHOT,\n",
    "        label_column_name=col,\n",
    "        annotations_key_value_criteria={'kingdom': ['Animalia']},\n",
    "        enable_novelty=True,\n",
    "        top_k=TOP_K,\n",
    "\n",
    "    )\n",
    "    coop_setup = Setup(\n",
    "        dataset_name=ImageDatasets.INATURALIST,\n",
    "        trainer_name=Trainers.COOP,\n",
    "        n_shots=16,\n",
    "        label_column_name=col,\n",
    "        annotations_key_value_criteria={'kingdom': ['Animalia']},\n",
    "        enable_novelty=True,\n",
    "        top_k=TOP_K,\n",
    "\n",
    "    )\n",
    "    \n",
    "    clip_metrics = AccuracyMetricEvaluator.load(clip_setup)['overall']\n",
    "    baseline_coop_metrics = AccuracyMetricEvaluator.load(baseline_coop_setup)['overall']\n",
    "    baseline_coop_metrics['trainer_name'] = 'baseline_coop'\n",
    "    coop_metrics = AccuracyMetricEvaluator.load(coop_setup)['overall']\n",
    "    \n",
    "    col_name = clip_setup.get_label_column_name() or 'default'\n",
    "    hierarchy_metrics = level_wise_accuracies_df[col]\n",
    "    hierarchy_metrics['trainer_name'] = 'hierarchy_coop'\n",
    "    plot_model_accuracy([clip_metrics, baseline_coop_metrics, coop_metrics, hierarchy_metrics], title=f\"Overall Perfmance on the '{col_name}' Column - Dataset: {clip_setup.get_dataset_name()}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3896efec-da19-4e7e-848c-399843855177",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(LEVEL_NAMES):\n",
    "    if col != 'default':\n",
    "        continue\n",
    "    \n",
    "    clip_setup = Setup(\n",
    "        dataset_name=ImageDatasets.INATURALIST,\n",
    "        trainer_name=Trainers.CLIP,\n",
    "        setup_type=Setups.EVAL_ONLY,\n",
    "        label_column_name=col,\n",
    "        annotations_key_value_criteria={'kingdom': ['Animalia']},\n",
    "        top_k=TOP_K,\n",
    "    )\n",
    "    baseline_coop_setup = Setup(\n",
    "        dataset_name=ImageDatasets.INATURALIST,\n",
    "        trainer_name=Trainers.COOP,\n",
    "        n_shots=16,\n",
    "        setup_type=Setups.EVAL_ONLY,\n",
    "        model_type=ModelType.ZERO_SHOT,\n",
    "        label_column_name=col,\n",
    "        annotations_key_value_criteria={'kingdom': ['Animalia']},\n",
    "        enable_novelty=True,\n",
    "        top_k=TOP_K,\n",
    "\n",
    "    )\n",
    "    coop_setup = Setup(\n",
    "        dataset_name=ImageDatasets.INATURALIST,\n",
    "        trainer_name=Trainers.COOP,\n",
    "        n_shots=16,\n",
    "        label_column_name=col,\n",
    "        annotations_key_value_criteria={'kingdom': ['Animalia']},\n",
    "        enable_novelty=True,\n",
    "        top_k=TOP_K,\n",
    "\n",
    "    )\n",
    "    \n",
    "    clip_metrics = AccuracyMetricEvaluator.load(clip_setup)['overall']\n",
    "    # baseline_coop_metrics = AccuracyMetricEvaluator.load(baseline_coop_setup)['overall']\n",
    "    # baseline_coop_metrics['trainer_name'] = 'baseline_coop'\n",
    "    coop_metrics = AccuracyMetricEvaluator.load(coop_setup)['overall']\n",
    "    \n",
    "    col_name = clip_setup.get_label_column_name() or 'default'\n",
    "    hierarchy_metrics = level_wise_accuracies_df[col]\n",
    "    hierarchy_metrics['trainer_name'] = 'hierarchy_coop'\n",
    "    plot_model_accuracy([clip_metrics, coop_metrics, hierarchy_metrics], title=f\"Overall Perfmance on the '{col_name}' Column - Dataset: {clip_setup.get_dataset_name()}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce59584-b359-4296-8b25-7d8d61da7463",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip",
   "language": "python",
   "name": "clip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
