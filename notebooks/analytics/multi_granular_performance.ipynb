{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7987e83",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76db7665-8df6-441e-88ea-a5222606eccf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../vlm_toolbox/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b6de1f-9d8b-4584-8557-a5237611243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587fb031-0380-462e-b99d-83409cacefc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "from config.annotations import AnnotationsConfig\n",
    "from config.enums import (\n",
    "    CLIPBackbones,\n",
    "    DataStatus,\n",
    "    Granularities,\n",
    "    ImageDatasets,\n",
    "    Modalities,\n",
    "    Setups,\n",
    "    Sources,\n",
    "    Stages,\n",
    "    Trainers,\n",
    ")\n",
    "from config.image_datasets import ImageDatasetConfig\n",
    "from config.model import ModelConfigManager\n",
    "from config.setup import Setup\n",
    "from config.train import TrainingArgumentsConfig\n",
    "from data.data_access.image_factory import ImageHandlerFactory\n",
    "from data.data_access.label_factory import LabelHandleFactory\n",
    "from data.data_access.text_factory import TextHandlerFactory\n",
    "from data.data_collate.factory import DataCollatorFactory\n",
    "from metric.accuracy import AccuracyMetricEvaluator\n",
    "from metric.visualization.accuracy import plot_model_accuracy\n",
    "from model.vlm_factory import VLMFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13efb01-f421-4390-b1f1-2303bf61a4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36b4f4a-c7ee-40f7-84c4-6a2552c0cb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flush():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61a0231-8d28-4954-b7db-1956f8ce07f1",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da8f5cd-7e77-4ac8-99b4-14b942adf54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d901b5-ff58-4c33-9552-4fd3ba84286a",
   "metadata": {},
   "source": [
    "### Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436ddc46-afdf-47d6-8f2f-b87c6c36bde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE_TYPE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE = torch.device(DEVICE_TYPE)\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92e2f77-13f4-48c5-9a46-d5ac2805615a",
   "metadata": {},
   "source": [
    "### Data Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1207fc68-8772-47d1-8a85-a8604ff822eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENABLE_FP16 = True\n",
    "dtype = torch.float16 if ENABLE_FP16 else torch.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b42bb3-720c-45e9-b38d-e6dd1596f891",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13715726-1348-406d-9a7b-a24a7f4baecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESS_BATCH_SIZE = 512\n",
    "BATCH_SIZE = 512\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050480e3-3679-4219-a7f2-e451df170199",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2747b5c0-377e-47d4-97d9-865bb5f7f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = Setup(\n",
    "    setup=Setups.FEW_SHOT,\n",
    "    metric_for_best_model=AccuracyMetricEvaluator.get_main_metric_name(),\n",
    "    dataset_name=ImageDatasets.IMAGENET_1K,\n",
    "    backbone_name=CLIPBackbones.CLIP_VIT_B_16,\n",
    "    trainer_name=Trainers.CLIP,\n",
    "    source=Sources.OPEN_AI,\n",
    "    granularity=Granularities.FINE,\n",
    "    validation_batch_size=BATCH_SIZE,\n",
    "    n_shots=16,\n",
    "    k_ways=53,\n",
    "    is_supervised=True,\n",
    ")\n",
    "setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09466a60-8de8-4be3-8ba5-b3039b2425da",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033ea7be-bff4-4ac5-8ed9-c54f48546fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_MODALITY_TYPE = DataStatus.EMBEDDING\n",
    "SPLIT = Stages.EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802955f4-3b9d-4dbf-bcd6-90044d9f3fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "annotations_config = AnnotationsConfig.get_config(dataset_name=setup.dataset_name)\n",
    "image_dataset_config = ImageDatasetConfig.get_config(setup, split=SPLIT, data_type=IMAGE_MODALITY_TYPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ea25f1-2f77-4e3f-83fd-eefbb0007049",
   "metadata": {},
   "source": [
    "# Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdd0f79-4be9-4103-9d79-35c531bf804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset_handler = (\n",
    "    ImageHandlerFactory.create_from_config(\n",
    "        Modalities.M1,\n",
    "        image_dataset_config,\n",
    "    )\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfbac6a-f018-4176-a4c0-9628cf05e95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(\n",
    "    label_handler,\n",
    "    image_dataset_handler=image_dataset_handler,\n",
    "    setup=setup,\n",
    "    checkpoint_path=CHECKPOINT_PATH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    split=SPLIT,\n",
    "    device_type=DEVICE_TYPE,\n",
    "    fp16=ENABLE_FP16,\n",
    "    \n",
    "):\n",
    "    class_id_label_id_adj_matrix = label_handler.get_class_id_label_id_adj_matrix()\n",
    "    text_dataset_handler = TextHandlerFactory.create_from_df(\n",
    "        Modalities.M2,\n",
    "        split,\n",
    "        label_handler.get_prompts_df(),\n",
    "    )\n",
    "    model_config = ModelConfigManager.get_config(\n",
    "        backbone_name=setup.backbone_name,\n",
    "        source=setup.source,\n",
    "        context_initialization=None,\n",
    "        trainer_name=setup.trainer_name,\n",
    "        labels=None if not setup.is_soft else label_handler.get_labels(),\n",
    "        label_id_prompt_id_mapping=None if not setup.is_soft else label_handler.get_label_id_prompt_id_mapping(),\n",
    "    )\n",
    "    \n",
    "    vlm = VLMFactory.from_pretrained(model_config=model_config).to(torch.device(device_type)).eval()\n",
    "    if checkpoint_path:\n",
    "        vlm.load_state_dict(torch.load(checkpoint_path))\n",
    "\n",
    "    for dataset_handler in [image_dataset_handler, text_dataset_handler]:\n",
    "        if not dataset_handler.is_embedded():\n",
    "            with torch.no_grad(), torch.autocast(device_type=device_type, dtype=dtype):\n",
    "                vlm.eval()\n",
    "                dataset_handler.to_embedding(\n",
    "                    vlm.get_embedding_fn_for_modality(dataset_handler.modality),\n",
    "                    batch_size=PREPROCESS_BATCH_SIZE,\n",
    "                )\n",
    "    text_dataset_handler = text_dataset_handler.to_prototypical_representation()\n",
    "    data_collator = DataCollatorFactory.create_multimodal_collator(\n",
    "        class_id_label_id_adj_matrix,\n",
    "        image_dataset_handler,\n",
    "        text_dataset_handler,\n",
    "        is_classification=True,\n",
    "    )\n",
    "    evaluation_args= TrainingArguments(\n",
    "        per_device_train_batch_size=setup.validation_batch_size,\n",
    "        per_device_eval_batch_size=setup.validation_batch_size,\n",
    "        metric_for_best_model=setup.metric_for_best_model,\n",
    "        label_names=data_collator.get_label_names(),\n",
    "        **TrainingArgumentsConfig.get_config(),\n",
    "    )\n",
    "   \n",
    "    metric_evaluator = AccuracyMetricEvaluator(\n",
    "        label_handler,\n",
    "        temperature=vlm.get_logit_scale().detach().cpu(),\n",
    "    )\n",
    "    image_dataset = image_dataset_handler.get_dataset(return_pt=True)\n",
    "    trainer = Trainer(\n",
    "        model=vlm,\n",
    "        args=evaluation_args,\n",
    "        train_dataset=image_dataset,\n",
    "        eval_dataset=image_dataset,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=metric_evaluator,\n",
    "    )\n",
    "    trainer.predict(image_dataset)\n",
    "    overall_accuracy_df = metric_evaluator.calculate_overall_accuracy()\n",
    "    overall_accuracy_df['model_name'] = setup.trainer_name\n",
    "    plot_model_accuracy(overall_accuracy_df, title=f'Accuracy Performance On {label_handler.label_column}')\n",
    "    return overall_accuracy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4e747f-2897-43d4-93ca-113c16e67358",
   "metadata": {},
   "source": [
    "## Standard Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4dd866-7f4e-498a-8d35-7f67ad3d5988",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_handler = (\n",
    "    LabelHandleFactory.create_from_config(annotations_config)\n",
    "    .config_prompts()\n",
    ").show()\n",
    "flush()\n",
    "experiment(label_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71b5179-4e6c-4d9f-a54a-c5ad8cc73ddd",
   "metadata": {},
   "source": [
    "## Evaluate on Coarse Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0440454b-f81b-4421-9d44-bba5fcab2e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_handler = (\n",
    "    LabelHandleFactory.create_from_config(annotations_config)\n",
    "    .update_label('coarse')\n",
    "    .config_prompts()\n",
    ").show()\n",
    "flush()\n",
    "experiment(label_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d41ba03-74a0-4816-b3fd-d1b13b86e86f",
   "metadata": {},
   "source": [
    "##  Evaluate on a Direct Parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d62fd6-cd9a-4f1e-bcd1-e1d2753ea745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_direct_parent_label(row):\n",
    "    parents_list = row['parents']\n",
    "    return parents_list[0].replace('_', ' ') if len(parents_list) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9204c3f3-2c22-4c13-a3a4-86649ce90e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_handler = (\n",
    "    LabelHandleFactory.create_from_config(annotations_config)\n",
    "    .add_column_to_metadata(get_direct_parent_label, 'direct_parent_label')\n",
    "    .update_label('direct_parent_label')\n",
    "    .config_prompts()\n",
    ").show()\n",
    "flush()\n",
    "experiment(label_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ba7758-95ef-4d43-a173-a394cebccf99",
   "metadata": {},
   "source": [
    "##  Evaluate on Direct Children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5eb6c3-4816-4e59-b8df-5db5f115a835",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subclasses_labels(row):\n",
    "    children_list = row['children']\n",
    "    return list(set(row['children'] + [row['class_label']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fa1571-228c-43c2-b162-3f4859063996",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_handler = (\n",
    "    LabelHandleFactory.create_from_config(annotations_config)\n",
    "    .add_column_to_metadata(get_subclasses_labels, 'child_label', flatten=True)\n",
    "    .config_prompts(apply_on_col='child_label')\n",
    ").show()\n",
    "flush()\n",
    "experiment(label_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cfb67b-190d-4750-8634-abe1a5725b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip",
   "language": "python",
   "name": "clip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
