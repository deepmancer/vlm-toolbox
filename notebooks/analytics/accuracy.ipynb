{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7795548e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc7e716-f7f4-42a8-bdec-0a40a4b2d405",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../vlm_toolbox/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec644e8-79c4-41df-9187-7f11e765181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3406a0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from config.annotations import AnnotationsConfig\n",
    "from config.enums import (\n",
    "    CLIPBackbones,\n",
    "    ImageDatasets,\n",
    "    LossType,\n",
    "    Metrics,\n",
    "    ModelType,\n",
    "    PrecisionDtypes,\n",
    "    Setups,\n",
    "    Trainers,\n",
    ")\n",
    "from config.setup import Setup\n",
    "from metric.classification import ClassificationMetricEvaluator\n",
    "from metric.visualization.accuracy import plot_model_accuracy\n",
    "from pipeline.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab5d7af-9de4-43cf-9109-cd759af663ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc5ded5-4d25-41f7-a96d-51d4038d6434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flush():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88234d35-2804-4abe-b8a4-6052c7e7d863",
   "metadata": {},
   "source": [
    "# Util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e82712-2c6e-4296-97ec-d5b6420b1555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_per_class_statistics(df, top_k):\n",
    "    total_samples_per_class = df['class_id'].value_counts().rename_axis('class_id').reset_index(name='total_samples')\n",
    "    final_df = total_samples_per_class[['class_id']].sort_values(by='class_id').reset_index(drop=True)\n",
    "    \n",
    "    for k in range(top_k):\n",
    "        pred_col = f'pred@{k+1}_label_id'\n",
    "        conf_col = f'pred@{k+1}_prob'\n",
    "\n",
    "        # Group by class_id and predicted class label\n",
    "        grouped = df.groupby(['class_id', pred_col]).agg(\n",
    "            frequency=(pred_col, 'count'),\n",
    "            average_confidence=(conf_col, 'mean')\n",
    "        ).reset_index()\n",
    "        grouped = pd.merge(grouped, total_samples_per_class, on='class_id')\n",
    "        grouped['normalized_frequency'] = grouped['frequency'] / grouped['total_samples']\n",
    "        \n",
    "\n",
    "        grouped = (\n",
    "            grouped\n",
    "            .rename(\n",
    "                columns={\n",
    "                    pred_col: f'pred_class_id@{k+1}',\n",
    "                    'average_confidence': f'confidence@{k+1}',\n",
    "                    'normalized_frequency': f'frequency@{k+1}'\n",
    "                }\n",
    "            )\n",
    "            [['class_id', f'pred_class_id@{k+1}', f'frequency@{k+1}', f'confidence@{k+1}']]\n",
    "        \n",
    "        )\n",
    "        pivot_df = grouped.loc[grouped.groupby('class_id')[f'frequency@{k+1}'].idxmax()].sort_values(by='class_id').reset_index(drop=True)\n",
    "       \n",
    "        final_df = pd.concat([final_df, pivot_df.drop(['class_id'], axis=1)], axis=1)\n",
    "\n",
    "    final_df['is_correct'] = final_df['class_id'] == final_df['pred_class_id@1']\n",
    "    return final_df\n",
    "\n",
    "def display_statistics(per_class_acc_df, col, y, group_by, title, class_cnt=10):\n",
    "    worst_df = per_class_acc_df.sort_values(by=[col], ascending=True).head(class_cnt).copy()\n",
    "    top_df = per_class_acc_df.sort_values(by=[col], ascending=False).head(class_cnt).copy()\n",
    "    gap_size = 5\n",
    "    all_dummy_dfs = pd.DataFrame()\n",
    "    for i in range(1, gap_size+1):\n",
    "        dummy_data = {col: [None] * gap_size, y: [\".\" * i] * gap_size, group_by: [None] * gap_size}\n",
    "        dummy_df = pd.DataFrame(dummy_data)\n",
    "        all_dummy_dfs = pd.concat([all_dummy_dfs, dummy_df])\n",
    "    \n",
    "    final_df = pd.concat([worst_df, all_dummy_dfs, top_df], ignore_index=True)\n",
    "    plt.figure(figsize=(17, int(8 * class_cnt / 10)))\n",
    "    barplot = sns.barplot(\n",
    "        data=final_df,\n",
    "        x=col,\n",
    "        y=y,\n",
    "        hue=group_by,\n",
    "        orient=\"h\",\n",
    "        saturation=1,\n",
    "        width=0.75,\n",
    "        dodge=False\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3c82c9",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e717565f-3a06-4fcc-81af-1ab90aa8834b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREPROCESS_BATCH_SIZE = 512\n",
    "RANDOM_STATE = 42\n",
    "TOP_K = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7d9d3d-90cb-4f77-83a8-eb414a89d264",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d28d75-ca83-4068-893a-5bf850645bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['phylum', 'class', 'order', 'family', 'genus', 'specific_epithet']\n",
    "setup = Setup(\n",
    "    dataset_name=ImageDatasets.INATURALIST,\n",
    "    backbone_name=CLIPBackbones.CLIP_VIT_B_16,\n",
    "    trainer_name=Trainers.COOP,\n",
    "    setup_type=Setups.FULL,\n",
    "    model_type=ModelType.FEW_SHOT,\n",
    "    num_epochs=100,\n",
    "    train_batch_size=1024,\n",
    "    n_shots=16,\n",
    "    validation_size=0.15,\n",
    "    label_column_name=columns[0],\n",
    "    annotations_key_value_criteria={'kingdom': ['Animalia']},\n",
    "    precision_dtype=PrecisionDtypes.FP16,\n",
    "    loss_type=LossType.LABEL_SMOOTHING_LOSS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a101b904-8889-49d3-bca3-a81aa6b7f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = ClassificationMetricEvaluator.load(setup)\n",
    "metrics_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f58235",
   "metadata": {},
   "source": [
    "# Load Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331d80a0-6afb-4d55-9bc1-ce3ac8229d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(setup=setup)\n",
    "pipeline.setup_labels()\n",
    "pipeline._initialize_metric_evaluator()\n",
    "metric_evaluator = pipeline.metric_evaluator\n",
    "label_handler = pipeline.label_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c416d4-5a74-4617-aee0-7ed9ad181b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_evaluator.register_metrics([\n",
    "    Metrics.BALANCED_ACCURACY,\n",
    "    Metrics.COHEN_KAPPA,\n",
    "    Metrics.M_CORR_COEFF,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6e05c6-9560-4f7b-969b-8d6dcfd7a028",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_config = AnnotationsConfig.get_config(dataset_name=setup.dataset_name)\n",
    "labels = label_handler.get_labels()\n",
    "prompts_df = label_handler.get_prompts_df()\n",
    "class_ids = label_handler.get_class_ids()\n",
    "class_id_label_id_adj_matrix = label_handler.get_class_id_label_id_adj_matrix()\n",
    "label_id_prompt_id_mapping = label_handler.get_label_id_prompt_id_mapping()\n",
    "classes_df = label_handler.get_classes_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1271371-e92a-4318-bb0a-8f1890f4bf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_sample_acc_df = metrics_dict['per_sample']\n",
    "per_sample_acc_df['is_correct'] = per_sample_acc_df['correct_pred_rank'] == 1\n",
    "\n",
    "per_class_acc_df = pd.DataFrame()\n",
    "\n",
    "for class_id, group in per_sample_acc_df.groupby('actual_label_id'):\n",
    "    class_accuracies = {'label_id': class_id}\n",
    "    for k in range(1, min(metric_evaluator.top_k, 1) + 1):\n",
    "        if k == 1:\n",
    "            group_metrics = metric_evaluator.get_metrics(predictions_df=group, main_metric_only=False, top_k=1)\n",
    "            class_accuracies.update(group_metrics.iloc[0].to_dict())\n",
    "        else:\n",
    "            top_k = group['correct_pred_rank'].apply(lambda x: x <= k and x != -1).mean()\n",
    "            class_accuracies[f'accuracy'] = top_k\n",
    "        class_accuracies['top_k'] = int(class_accuracies['top_k'])\n",
    "        class_accuracies['group_cnt'] = len(group)\n",
    "    per_class_acc_df = pd.concat([per_class_acc_df, pd.DataFrame([class_accuracies])], ignore_index=True)\n",
    "\n",
    "overall_acc_df = metric_evaluator.get_metrics(predictions_df=per_sample_acc_df, main_metric_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f1d557-3e8d-404c-bd88-acc0268d390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e61871a-9e87-4e19-858b-0b0276818b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(per_class_acc_df['label_id'], per_class_acc_df['group_cnt']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f6fa9c-b7bc-413f-9e06-a83864d839f3",
   "metadata": {},
   "source": [
    "# Visualize Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cd67b3-0634-49d6-a8a2-1c0f2f8880ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_accuracy(overall_acc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d16b65-41e4-4ba0-9936-dd9be7238735",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 8))\n",
    "g = sns.histplot(per_sample_acc_df, x='pred@1_prob', hue='is_correct', stat='probability')\n",
    "g.set_yscale(\"log\")\n",
    "plt.xlabel('Confidence', fontsize=13)\n",
    "plt.ylabel('Density', fontsize=13)\n",
    "plt.title(f'Samples\\' Top-1 Prediction\\'s Confidence Histogram', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f6199a-e272-48ec-b277-6aab3c55d1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.ones_like(per_class_acc_df['accuracy'].to_numpy()) / per_class_acc_df.shape[0]\n",
    "plt.figure(figsize=(9, 6))\n",
    "bins = 50\n",
    "\n",
    "plt.hist([per_class_acc_df['top_1_accuracy']], bins=bins, label=['Top-1'], alpha=0.5, weights=weights)\n",
    "plt.hist([per_class_acc_df['top_3_accuracy']], bins=bins, label=['Top-3'], alpha=0.5, weights=weights)\n",
    "plt.hist([per_class_acc_df['top_5_accuracy']], bins=bins, label=['Top-5'], alpha=0.5, weights=weights)\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"Top5 & Top-3 & Top-1 Acc. Per Class\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a792f7-1494-41ef-9071-3d4a732082dd",
   "metadata": {},
   "source": [
    "## Class-wise Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c57606-c006-4d9a-ad55-21400c786a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_grained_col = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a38f79-adfd-4c8d-8387-794b52a63851",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_statistics(\n",
    "    per_class_acc_df,\n",
    "    'top_1_accuracy',\n",
    "    'label',\n",
    "    coarse_grained_col,\n",
    "    'Top-1 Worst & Best Acc. Performance',\n",
    "    class_cnt=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79ebc14-c2a6-4d76-88e5-96a7c03c6ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_statistics(\n",
    "    per_class_acc_df,\n",
    "    'top_3_accuracy',\n",
    "    'label',\n",
    "    coarse_grained_col,\n",
    "    'Top-3 Worst & Best Acc. Performance',\n",
    "    class_cnt=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41b2ef6-0c7b-4b48-a786-a5c6a82fc691",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_statistics(\n",
    "    per_class_acc_df,\n",
    "    'top_5_accuracy',\n",
    "    'label',\n",
    "    coarse_grained_col,\n",
    "    'Top-5 Worst & Best Acc. Performance',\n",
    "    class_cnt=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d3627a-841c-4ab1-a0a2-8a3a9ba85e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip",
   "language": "python",
   "name": "clip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
